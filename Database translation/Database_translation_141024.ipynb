{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JJnnqgshdv35",
        "outputId": "36b510d8-9c84-418d-f65e-181d822e149e"
      },
      "outputs": [],
      "source": [
        "# Importar e instalar dependencias\n",
        "!pip install sacremoses\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSG-vt26dq8h"
      },
      "source": [
        "# CARGA DE DATOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hItISHlWd33J",
        "outputId": "c0eacbe3-babb-4f59-9914-404a5180df34"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "# Descarga el archivo del dataset de drive usando gdown\n",
        "url = 'https://drive.google.com/file/d/1LkEJ3rstkdyhUGWi9O2YKQMe0wC_ZyDd/view?usp=sharing'\n",
        "file_id = url.split('/')[-2]\n",
        "!gdown --id $file_id\n",
        "\n",
        "# Carga el dataset usando pandas\n",
        "sd = pd.read_csv('/content/Suicide_Detection.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNiankLcO2v-",
        "outputId": "32d97b2f-b8d6-4c9a-922b-1bf7cb199a41"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, MarianTokenizer, MarianMTModel\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "!pip install sacremoses\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Sample data for testing purposes\n",
        "sd_t = sd.sample(n=200, random_state=None)\n",
        "\n",
        "# Load a specific tokenizer and model\n",
        "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\", clean_up_tokenization_spaces=True)\n",
        "model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")\n",
        "\n",
        "# Create a translation pipeline with the specified tokenizer and model\n",
        "translator = pipeline(\"translation_en_to_es\", model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "def translate_batch(texts, batch_size=32):  # Adjust batch_size for your GPU memory\n",
        "    translations = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size)):\n",
        "        batch = texts[i:i + batch_size]\n",
        "        # Tokenize the batch of texts\n",
        "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)  # Move inputs to the device\n",
        "        # Generate translations\n",
        "        translated_batch = model.generate(**inputs)\n",
        "        # Decode translations\n",
        "        decoded_batch = tokenizer.batch_decode(translated_batch, skip_special_tokens=True)\n",
        "        translations.extend(decoded_batch)\n",
        "    return translations\n",
        "\n",
        "# Translate the texts in batches\n",
        "sd_t['spanish_text'] = translate_batch(sd_t['text'].tolist())\n",
        "\n",
        "# Verify by printing the first few rows\n",
        "print(sd_t.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_zRsCVmDXkz",
        "outputId": "821deffb-150c-46d8-ca3c-3867282c0969"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define la ruta donde quieres guardar el archivo en tu Google Drive\n",
        "file_path = '/content/drive/MyDrive/Suicide_Detection_translated_5.csv'\n",
        "\n",
        "# Guarda el DataFrame en un archivo CSV en Google Drive\n",
        "sd_t.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "M2eIF76Z-DC-",
        "outputId": "280b8ec9-92a3-4aa4-d68e-b89244f2bc8d"
      },
      "outputs": [],
      "source": [
        "sd_t.head(20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
