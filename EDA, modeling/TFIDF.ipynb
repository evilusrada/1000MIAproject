{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JJnnqgshdv35"
      },
      "outputs": [],
      "source": [
        "# Importar e instalar dependencias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSG-vt26dq8h"
      },
      "source": [
        "# CARGA DE DATOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmUPRsiaaDE9",
        "outputId": "6daeff81-d8c6-4804-e92b-fbfbbc18590f"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "# Descarga el archivo del dataset de drive usando gdown\n",
        "url = 'https://drive.google.com/file/d/1z3fmc6QKE71_OQ3Poy-fTq1DpJcoK-Z_/view?usp=drive_link'\n",
        "file_id = url.split('/')[-2]\n",
        "!gdown --id $file_id\n",
        "\n",
        "# Carga el dataset usando pandas\n",
        "sd = pd.read_csv('/content/Suicide_Detection_clean_2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNiankLcO2v-"
      },
      "outputs": [],
      "source": [
        "# Sampleo de data para agilizar el testeo del código\n",
        "# sd = sd.sample(n=50000, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ql_eMf_Z6HI"
      },
      "source": [
        "# MODELADO, ENTRENAMIENTO Y EVALUACIÓN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn8i7ejUelLM"
      },
      "outputs": [],
      "source": [
        "#Copia del dataset limpio (pre_processed)\n",
        "pre_processed = sd.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSrvpZYyhGV2",
        "outputId": "80560924-3fbf-495a-f86a-3a3e4e807c12"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separación de dataset en training y testing\n",
        "train_data ,test_data = train_test_split(pre_processed,test_size=0.2,random_state=10)\n",
        "\n",
        "print('Training data: ',len(train_data))\n",
        "print('Testing data: ',len(test_data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiGFVk0zoy-4"
      },
      "source": [
        "### Modelo de regresión logística basado en TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyJ2YPxOIdWg"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, classification_report, recall_score, f1_score, confusion_matrix,  classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# TF-IDF\n",
        "vectorizer_tfidf = TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2))\n",
        "X_tfidf_train = vectorizer_tfidf.fit_transform(train_data['text'])\n",
        "X_tfidf_test = vectorizer_tfidf.transform(test_data['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iclkMYybo2ku",
        "outputId": "ed143b1c-702a-4d33-fce9-273c0148b8cd"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del modelo\n",
        "model = LogisticRegression(penalty='l2', C=100, solver='lbfgs', max_iter=100)\n",
        "model.fit(X_tfidf_train, train_data['class'])\n",
        "\n",
        "# Evaluación del modelo\n",
        "predictions_tfidf = model.predict(X_tfidf_test)\n",
        "accuracy_tfidf = accuracy_score(test_data['class'], predictions_tfidf)\n",
        "precision_tfidf = precision_score(test_data['class'], predictions_tfidf, average='weighted')\n",
        "recall_tfidf = recall_score(test_data['class'], predictions_tfidf, average='weighted')\n",
        "f1_tfidf = f1_score(test_data['class'], predictions_tfidf, average='weighted')\n",
        "confusion_mat_tfidf = confusion_matrix(test_data['class'], predictions_tfidf)\n",
        "\n",
        "print(classification_report(test_data['class'], predictions_tfidf))\n",
        "\n",
        "print(\"Accuracy:\", accuracy_tfidf)\n",
        "print(\"Precision:\", precision_tfidf)\n",
        "print(\"Recall:\", recall_tfidf)\n",
        "print(\"F1-Score:\", f1_tfidf)\n",
        "print(\"Confusion Matrix:\\n\", confusion_mat_tfidf)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
